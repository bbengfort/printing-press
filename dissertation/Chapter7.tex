%Chapter 7

\renewcommand{\thechapter}{7}

\chapter{Related Work}
\label{ch:related_work}

Our work is heavily inspired by the OceanStore~\cite{oceanstore} project and its prototype, Pond~\cite{pond}.
Before Amazon Web Services, Google Cloud, or Microsoft Azure, OceanStore changed the way researchers thought about wide area distributed systems, transforming the literature to consider truly global services and directly leading to research platforms like PlanetLab~\cite{planetlab}.
Our goal is to provide a consistency-centric model for global scale systems that enables the same type of research platform.
We target a globally distributed file system as a primary application because it serves a wide cross-section of systems research from databases to networking and operating systems.

The OceanStore model was based on an untrusted infrastructure and therefore relied on byzantine fault tolerance~\cite{byzantine-generals, byzantine_fault_tolerance,fail-stop,ho_nysiad_2008,kotla_zyzzyva_2007,singh_zeno_2009}.
Around the same time, other distributed systems like the Farsite file system~\cite{farsite,farsite_byzantine} and PBFT~\cite{pbft} also principally considered byzantine agreement instead of performance.
The rise of cloud services shifted the focus to trusted infrastructure and high throughput file systems such as Ceph~\cite{ceph} and GFS/HDFS~\cite{gfs,hdfs,hadoop_hdfs}.
We do not foresee an abatement of the trusted infrastructure assumption either, as more recent work in large distributed file systems such as CalvinFS~\cite{calvinfs}, Giga+~\cite{giga+,giga+_scale}, IndexFS~\cite{indexfs} and GlobalFS~\cite{globalfs} all make the same assumptions.
Even if a cloud provider is not trusted, a trust layer can be created on the cloud using models similar to SUNDR~\cite{sundr} or securely across multiple providers using SPORC~\cite{sporc}.

The shift to cloud providers also shifted research away from file systems toward application-specific databases.
In Chapter~\ref{ch:architecture} we described the evolution of cloud database design, from relaxed consistency models~\cite{bigtable,dynamo,pnuts,cassandra,hbase} to much stronger consistency~\cite{megastore,spanner,aurora}.
Figure~\ref{fig:ch02_distributed_architecture} generalized these models by describing how they provide global consistency by sharding the namespace to specific geographic regions.
Systems that implement many small quorums of coordination~\cite{mdcc,scatter,spanner} avoid the centralization bottleneck and reliability concerns of master-service systems~\cite{gray_dangers_1996,gfs} but create silos of independent operation that are not coordinated with respect to each other.
In order to externalize a single consistent view, these systems rely on a complex multi-process architecture that makes it difficult to reason about the many layers of replication and consistency.

Our work unifies these ideas into a consistency-centric model for globally distributed systems.
We propose a single system based on a key/value object store that is federated in both a cloud environment and in a heterogeneous fog.
This unification makes it simpler to reason about consistency and to build complex distributed applications.
In the next sections we will conclude our related work by describing work related to hierarchical consensus and federated consistency.

\section{Hierarchical Consensus}

Our principle contribution is Hierarchical Consensus, a general technique to compose consensus groups, maintain consistency invariants over large systems, and adapt to changing conditions and application loads.
HC is related to the large body of work improving throughput in distributed consensus over the Paxos protocol~\cite{paxos,epaxos,fexible_paxos,generalized_paxos}, and on Raft~\cite{raft,raft_refloated}.
These approaches focus on fast vs. slow path consensus, eliding phases with dependency resolution, and load balancing.

Our work is also orthogonal in that subquorums and the root quorums can be implemented with different underlying protocols, though the two levels must be integrated quite tightly.
Further, HC abstracts reconfiguration away from subquorum consensus, allowing multiple subquorums to move into new configurations and reducing the need for joint consensus~\cite{raft} and other heavyweight procedures.
Finally, its hierarchical nature allows the system to multiplex multiple consensus instances on disjoint partitions of the object space while still maintaining global consistency guarantees.
% We describe some key differences between different distributed consensus protocols in Table~\ref{tab:distributed_consensus_comparison}.
%
% \begin{landscape}
% \renewcommand{\baselinestretch}{1}
% \small\normalsize
%  \begin{table}
% \caption[Comparison of Distributed Consensus]{A comparison of distributed consensus algorithms in a variety of scenarios.}
% \begin{center}
% \begin{tabular}{|p{1.6in}|p{1.6in}|p{1.6in}|p{1.6in}|p{1.6in}|}
% \hline
% \textbf{Scenario} & \textbf{Raft} & \textbf{ePaxos} & \textbf{Vertical Paxos} & \textbf{Hierarchical Consensus} \\
% \hline \hline
% Reads & Immediate response from leader (forward to leader). & Response from any replica after dependency resolution. & Read quorums overlap with write quorums to respond to requests. & Forward to leader of subquorum who responds or remote reads if required. \\
% \hline
% \end{tabular}
% \end{center}
% \label{tab:distributed_consensus_comparison}
% \end{table}
%  \renewcommand{\baselinestretch}{2}
% \small\normalsize
% \end{landscape}

The global consistency guarantees of HC are in direct contrast to other systems that scale by exploiting multiple consensus instances~\cite{bigtable,mdcc,megastore} on a per-object basis.
These systems retain the advantage of small quorum sizes but cannot provide system-wide consistency invariants.
Another set of systems uses quorum-based decision-making but relaxes consistency guarantees~\cite{dynamo,pnuts,cops}; others provide no way to pivot the entire system to a new configuration~\cite{scatter}.
Chain replication~\cite{van2004chain} and Vertical Paxos~\cite{vertical_paxos} are among approaches that control Paxos instances through other consensus decisions.
However, HC differs in the deep integration of the two different levels.
Whereas these approaches are top down, HC consensus decisions at the root level replace system configuration at the subquorum level, and vice versa.

Possibly the closest system to HC is Scatter~\cite{scatter}, which uses an overlay to organize consistent groups into a ring.
Neighbors can join, split, and talk amongst themselves. The bottom-up approach potentially allows scaling to many subquorums, but the lack of central control makes it hard to implement global re-maps beyond the reach of local neighbors.
HC ties the root quorum and subquorums tightly together, allowing root quorum decisions to completely reconfigure the running system on the fly either on demand or by detecting changes in network conditions.

We claim very strong consistency across a large distributed system, similar to Spanner~\cite{spanner} and CalvinFS~\cite{calvindb,calvinfs}.
Spanner provides linearizable  transactions through use of special hardware and environments, which are used to tightly synchronize clocks in the distributed setting.
Spanner therefore relies on a very specific, curated environment.
HC targets a wider range of systems that require cost effective scaling in the data center to rich dynamic environments with heterogeneity on all levels.
CalvinFS~\cite{calvindb,calvinfs} batches transaction operations across the wide area to minimize communication, but still requires a geographically replicated Paxos instance to coordinate transactions.

Finally, shared logs have proven useful in a number of settings from fault tolerance to correctness guarantees.
However, keeping such logs consistent in even a single consensus instance has proven difficult~\cite{chubby,gfs,zookeeper}.
More recent systems are leveraging hardware support to provide fast access to shared logs~\cite{vcorfu,tango,hyder-a,fawn}.
To our knowledge, HC is the first work to propose synchronizing shared logs across multiple discrete consensus instances in the wide area.

\section{Federated Consistency}

One of the earliest attempts to hybridize weak and strong consistency was a
model for parallel programming on shared memory systems by Agrawal et al
\cite{hybrid_consistency}.
This model allowed programmers to relax strong consistency in certain contexts
with causal memory or pipelined random access in order to improve parallel
performance of applications.
Per-operation consistency was extended to distributed storage by the RedBlue
consistency model of Li et al \cite{redblue}.
Here, replication operations are broken down into small, commutative
sub-operations that are classified as red (must be executed in the same order
on all replicas) or blue (execution order can vary from site to site), so long
as the dependencies of each sub-operation are maintained.
The consistency model is therefore global, specified by the red/blue ordering
and can be adapted by redefining the ratio of red to blue operations, e.g.
all blue operations is an eventually consistent system and all red is
sequential.

The next level above per-operation consistency hybridization is called
\textit{consistency rationing} wherein individual objects or groups of objects
have different consistency levels applied to them to create a global quality
of service guarantee.
Kraska et al.~\cite{consistency_rationing} initially proposed consistency rationing be on a per-transaction basis by classifying objects in three tiers: eventual, adaptable, and linearizable.
Objects in the first and last groups were automatically assigned transaction
semantics that maintained that level of consistency; however objects assigned
the adaptable categorization had their consistency policies switched at
runtime based on a cost function that either minimized time or write costs
depending on user preference.
This allowed consistency in the adaptable tier to be flexible and responsive
to usage.

Chihoub et al.
extended the idea of consistency rationing and proposed limiting the number of
stale reads or the automatic minimization of some consistency cost metric by
using reporting and consistency levels already established in existing
databases \cite{harmony,harmony_money}.
Here multiple consistency levels are being utilized, but only one consistency
model is employed at any given time for all objects, relaxing or strengthening
depending on observed costs.
By utilizing all possible consistency semantics in the database, this model
allows a greater spectrum of consistency guarantees that adapt at runtime.

Al-Ekram and Holt \cite{multi_consistency} propose a middleware
based scheme to allow multiple consistency models in a single distributed
storage system.
They identify a similar range of consistency models, but use a middleware
layer to forward client requests to an available replica that maintains
consistency at the lowest required criteria by the client.
However, although their work can be extended to deploying several consistency
models in one system, they still expect a homogeneous consistency model that
can be swapped out on demand as client requirements change.
Additionally their view of the ordering of updates of a system is from one
versioned state to another and they apply their consistency reasoning to the
divergence of a local replica's state version and the global version.
Similar to SUNDR, proposed by Li et al.
\cite{sundr}, an inconsistency is a fork in the global ordering of
reads and writes (a ``history fork'').
Our consistency model instead considers object forks, a more granular level
that allows concurrent access to different objects without conflict while
still ensuring that no history forks can happen.

Hybridization and adaptation build upon previous work that strictly
categorizes different consistency schemes.
An alternative approach is to view consistency along a continuous scale with
several axes that can be tuned precisely.
Yu and Vahdat \cite{conit_continous_consistency} propose the \textit{conit}, a consistency
unit described as a three dimensional vector that describes tolerable
deviations from linearizability along staleness, order error, and numeric
ordering.
Similarly, Afek et al.~\cite{quasi_linearizability} present quasi-linearizable histories
which specify a bound on the relative movement of ordered items in a log which
make it legally sequential.
