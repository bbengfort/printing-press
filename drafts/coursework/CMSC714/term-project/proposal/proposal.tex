\documentclass[11pt,letterpaper]{article}

\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage[parfill]{parskip}
\usepackage{subcaption}

\pagestyle{fancyplain}
\fancyhf{}
\fancyfoot[R]{\footnotesize Page \thepage\ of \pageref{LastPage}}

\renewcommand{\headrulewidth}{0.0pt} % No header rule
\renewcommand{\footrulewidth}{0.4pt} % Thin footer rule

\begin{document}

\title{Streaming Project Proposal}
\author[1]{Benjamin Bengfort}
\author[2]{Allen Leis}
\author[1]{Konstantinos Xirogiannopoulos}
\affil[ ]{Department of Computer Science}
\affil[ ]{University of Maryland}
\affil[1]{\textit{\{bengfort,kostasx\}@cs.umd.edu}}
\affil[2]{\textit{aleis@umd.edu}}

\date{October 12, 2015}

\maketitle
\section*{Introduction}

The widespread adoption of distributed computing frameworks and tools has led to a ``data flow'' model of data analysis. Data flows are described as directed graphs whose nodes represent a single computation and whose edges represent data transmission of input and output values. Describing computation this way is simple, flexible, and when mapped to a distributed topology, scalable. In particular, data flow models have been used successfully for real-time analysis of ``streaming'' datasets, that is datasets that are unbounded and/or unordered. Incoming information is streamed into the open capture node of the analytical graph, then is forwarded to other nodes for processing.

The most popular Streaming frameworks include either a DSL or programming model that allows programmers to specify a data flow topology; then parallelizes the computation across a cluster of homogenous compute nodes. For example, Discretized Streams (DStreams) are an extension of the RDD model in Spark that allow the application of transformations and actions on a time based portion (a time window) of a partitioned collection of data objects \cite{zaharia2012discretized}. Twitter Storm more explicitly defines the computational topology in the form of Bolts and Spouts such that a wide array of analyses can be performed on a variety of tuples in parallel at various points in the processing \cite{toshniwal2014storm}. While both Storm and DStreams are micro-batched, Google DataFlow \cite{akidau2015dataflow} and Naiad \cite{murray2013naiad} attempt to prove that no matter the execution engine (micro-batch, batch, or true streaming), the data flow model leads to a correct, scaling form of real time computation.

Although these approaches are currently being used in a wide array of domains including intrusion detection, internet browsing activity, sensors, and news aggregation, the data flow approach ignores lessons learned in the HPC community. In particular, due to the serial nature of data flow models, compute nodes are not automatically load balanced and can easily become under utilized. Moreover, these systems employ no interprocess communication between workers, meaning that computation composed of multiple data manipulations requires the full completion of multiple upstream compute nodes, thus limiting parallelism. In this project, we hope to explore HPC techniques typically used in the scientific domain and reason about their applications to these new streaming methodologies.


\section*{Proposals}

Below, we enumerate a few kernels of ideas that may be interesting to pursue as research projects for the purposes of the course at first, and then to push forward towards potential publication.

\begin{enumerate}

    \item \textbf{Discrete Event Simulation} We have noticed that many streaming applications compute approximations designed to detect anomalies or trends in discrete events (e.g. web clicks, newsworthy items, or sensor events). We propose that Discrete Event Simulation (DES) techniques, which use behavioral models, Bayesian networks and timed-transition automata, might be directly applied to data flow topologies to increase parallelism for similar approximations. In particular, we note the parallelizable (though somewhat complex) approach identified in \cite{klerx2014model} for further investigation.

    \item \textbf{Accelerated Streaming via Communication Between Streams}
    Streaming algorithms traditionally incorporate discrete streams of data that flow through layers of computation. If we were to assemble an appropriate set of streaming algorithms and try to reason about ways that communication between the streams would be beneficial. This would involve coming up with novel ideas and techniques for accelerating computation and doing experiments to see what the trade-offs and differences would be. Our hope is that while studying these algorithms, we will be able to come up with ways portions of the algorithms could be accelerated and be able to implement and evaluate those ideas.

\end{enumerate}

\bibliographystyle{plain}
\bibliography{papers}

\end{document}
